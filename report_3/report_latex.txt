\documentclass[conference]{IEEEtran}

% ---------- Packages ----------
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{float}
\usepackage{placeins}
\usepackage{subcaption}


% ---------- BibTeX ----------
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% ---------- Title ----------
\title{Segmentation of COVID19 X-ray images}

\author{
\IEEEauthorblockN{Nguyen Minh Dat}
\IEEEauthorblockA{
Machine Learning in Medicine\\
USTH University\\
Email: datnm.23bi14089@usth.edu.vn
}
}

\begin{document}

\maketitle

\section{Introduction}
The COVID-19 pandemic spread rapidly from 2020 to 2024. According to statistics from the Vietnamese Ministry of Health, by June 2023 there were 11,619,451 confirmed cases, including 43,206 deaths, accounting for about 0.4\% of total infections. This was a very dangerous pandemic. Many scientific studies have shown that COVID-19 can cause damage to internal organs, especially the lungs. Therefore, this study aims to identify and mark damaged regions in the lungs of COVID-19 patients.

\section{Data Description}
\subsection{Data organization}
The dataset used in this study is the COVID-QU-Ex dataset from Kaggle, which contains X-ray images of patients. This dataset consists of two parts: Lung Segmentation Data and COVID-19 Infection Segmentation Data. In this research, only the COVID-19 Infection Segmentation Data is used to detect damaged regions. The dataset is organized with the following directory structure:

\begin{verbatim}
Infection Segmentation Data/
│───├── train/
│   │   ├── COVID-19/
│   │   │       ├── images/
│   │   │       ├── infection masks
│   │   │       ├── lung masks
│   │   └── Non-COVID/
│   │   │       ├── images/
│   │   │       ├── infection masks
│   │   │       ├── lung masks
│   │   └── Normal/
│   │   │       ├── images/
│   │   │       ├── infection masks
│   │   │       ├── lung masks
│───├── val/
│   │   ├── COVID-19/
│   │   └── Non-COVID/
│───└── test/
│   │   ├── COVID-19/
│   │   └── Non-COVID/
\end{verbatim}

\begin{table}[htbp]
\centering
\caption{Dataset description}
\label{tab: Number of images for training and testing}
\begin{tabular}{|l|c|p{7cm}|}
\hline
\textbf{Name} & \textbf{Number of images} \\ \hline
Train & 1864 COVID and 932 non-COVID \\ \hline
Validation & 466 COVID and 233 non-COVID \\ \hline
Test & 583 COVID and 292 non-COVID\\ \hline
\end{tabular}
\end{table}

\subsection{Data training}
I use two data groups, COVID and non-COVID, for model training. Each group is split into training, validation, and test sets, including X-ray images and corresponding infection masks indicating lung damage. In infection masks, COVID patients show white regions representing infected lung areas, whereas non-COVID patients do not show any marked regions. This data selection is well-balanced and suitable for training the proposed model.

\section{Model selection}
In this study, an Attention U-Net model is used to segment COVID-19 infection regions from chest X-ray images. By adding attention gates to the skip connections, the model can focus more on important infected areas and reduce the influence of background and healthy tissues. This architecture is well-suited for medical image segmentation, especially when infected regions are small and imbalanced, helping to improve localization and overall segmentation performance. In addition, I also experimented with another U-Net variant called ResNet U-Net, which was trained by my friend, Pham Minh Hieu. We used the same dataset, and the goal was to compare the differences between his model and mine under the same conditions.

\subsection{Attention U-net}
Attention U-Net is built on the standard U-Net architecture. The encoder consists of regular convolution blocks. Attention Gates are integrated into the skip connections. These attention gates combine information from both the encoder and the decoder to create attention maps and filter out unimportant features. The decoder then uses these attention-filtered features to reconstruct the final mask.

Strengths
This model can focus well on important lesion regions and reduce the effect of background noise. It is especially effective when the lesions are small, have blurry boundaries, or are unevenly distributed. Therefore, it is very suitable for high-precision medical image segmentation tasks.

\subsection{ResNet U-Net model}
Architecture
ResNet U-Net is based on the U-Net structure with an encoder, bottleneck, and decoder. The encoder is replaced by a ResNet backbone (for example, ResNet-34) pretrained on ImageNet. It uses residual blocks in the encoder to extract deeper features. Skip connections directly transfer feature maps from the encoder to the decoder. The decoder contains upsampling and convolution layers to restore the image resolution. The final layer is a 1×1 convolution that generates a binary mask.

Strengths
This model has a strong feature extraction ability thanks to the pretrained ResNet. It usually converges faster and more stably during training. It works well with small to medium-sized datasets and is widely used and validated in medical image segmentation tasks.

\subsection{Overall Comparison}
ResNet U-Net mainly focuses on strong feature extraction and is suitable when a stable and easy-to-train model is needed. In contrast, Attention U-Net concentrates more on important regions in the image, making it more appropriate when high accuracy is required, especially for small lesion areas.

\section{Results}
\subsection{Results of Attention U-Net}
\subsubsection{Result of training}

These are the training results after 30 epochs:

\begin{table}[htbp]
\centering
\caption{Training and validation performance over epochs for Attention U-Net}
\label{tab:training_results}
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|cc|ccc}
\hline
\textbf{Epoch} & \textbf{Train Loss} & \textbf{Train Dice} & \textbf{Val Loss} & \textbf{Val COVID Dice} & \textbf{Val Non-COVID Dice} \\
\hline
1  & 0.6550 & 0.3460 & 0.5712 & 0.6006 & 0.0000 \\
2  & 0.5581 & 0.3900 & 0.5040 & 0.6248 & 0.0000 \\
3  & 0.5163 & 0.4060 & 0.4718 & 0.6502 & 0.0000 \\
4  & 0.4945 & 0.4179 & 0.4657 & 0.6790 & 0.0086 \\
5  & 0.4802 & 0.4271 & 0.4659 & 0.6827 & 0.0687 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
25 & 0.3805 & 0.5678 & 0.3791 & 0.7182 & 0.4893 \\
26 & 0.3763 & 0.5919 & 0.3688 & 0.7192 & 0.4421 \\
27 & 0.3699 & 0.5944 & 0.3893 & 0.6921 & 0.0558 \\
28 & 0.3692 & 0.5968 & 0.3764 & 0.7309 & 0.6137 \\
29 & 0.3656 & 0.6081 & 0.4092 & 0.7028 & 0.6524 \\
30 & 0.3675 & 0.5930 & 0.3946 & 0.7275 & 0.4464 \\
\hline
\end{tabular}}
\end{table}
In the final epochs, the model converged stably with low training and validation loss. The training Dice stayed around 0.59–0.61, while the validation COVID Dice remained high and stable at about 0.72–0.73, indicating good segmentation performance and generalization. The validation of the Non-COVID Dice also improved compared to the early stage. No serious overfitting was observed, and the best overall performance appeared in the last epochs, making them suitable for final model selection.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{img_0_image.png}
        \caption{Original image}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{img_0_gt.png}
        \caption{Ground truth mask}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{img_0_overlay.png}
        \caption{Prediction overlay}
    \end{subfigure}

    \caption{COVID sample: original image, ground truth mask, and predicted segmentation overlay}
    \label{fig:attention_unet_results}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{img_620_image.png}
        \caption{Original image}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{img_620_gt.png}
        \caption{Ground truth}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{img_620_overlay.png}
        \caption{Prediction overlay}
    \end{subfigure}

    \caption{Non-COVID sample: original image, ground truth mask, and predicted segmentation overlay}
    \label{fig:noncovid_example}
\end{figure}
\begin{table}[htbp]
\centering
\caption{Overall prediction performance on the test set}
\label{tab:prediction_results}
\begin{tabular}{lc}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Mean Dice & 0.6926 \\
Mean IoU  & 0.6095 \\
\hline
\end{tabular}
\end{table}

I observed that the red predicted regions do not completely match the ground truth masks when representing the infected areas of COVID-19 patients. For non-COVID patients, the predicted masks usually contain no red regions or only very small ones. This indicates that the model performs better on the non-COVID set than on the COVID cases.

\subsection{Results of ResNet U-Net}
\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{covid_1579_image.png}
        \caption{Original image}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{covid_1579_gt.png}
        \caption{Ground truth}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{covid_1579_overlay.png}
        \caption{Prediction overlay}
    \end{subfigure}

    \caption{COVID sample: original CT image, ground truth infection mask, and predicted segmentation overlay}
    \label{fig:covid_example}
\end{figure}
\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{non_COVID (3248)_image.png}
        \caption{Original image}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{non_COVID (3248)_gt.png}
        \caption{Ground truth}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{non_COVID (3248)_overlay.png}
        \caption{Prediction overlay}
    \end{subfigure}

    \caption{Non-COVID sample: original CT image, ground truth infection mask, and predicted segmentation overlay}
    \label{fig:noncovid_example}
\end{figure}
\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{non_COVID (3248)_image.png}
        \caption{Original image}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{non_COVID (3248)_gt.png}
        \caption{Ground truth}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{non_COVID (3248)_overlay.png}
        \caption{Prediction overlay}
    \end{subfigure}

    \caption{Non-COVID sample: original CT image, ground truth infection mask, and predicted segmentation overlay}
    \label{fig:noncovid_example}
\end{figure}
\begin{table}[htbp]
\centering
\caption{Prediction performance for COVID and Non-COVID cases}
\label{tab:covid_noncovid_prediction}
\begin{tabular}{lcc}
\hline
\textbf{Category} & \textbf{Mean Dice} & \textbf{Mean IoU} \\
\hline
COVID     & 0.7701 & 0.6650 \\
Non-COVID & 0.2911 & 0.2911 \\
\hline
\end{tabular}
\end{table}

For the ResNet U-Net model, I consider the predicted masks for COVID patients to be better than those from the Attention U-Net. The red-highlighted regions cover the infected areas more completely and are closer to the ground-truth labels. However, on the non-COVID dataset, the model is less accurate and does not learn the patterns as well.

\section{Conclusion}
This study explored COVID-19 lung infection segmentation on chest X-ray images using the COVID-QU-Ex dataset with two models: Attention U-Net and ResNet U-Net. Both models converged stably and learned meaningful features. Attention U-Net showed more balanced performance and better results on non-COVID samples, while ResNet U-Net produced more accurate and complete segmentation on COVID infection regions but was weaker on non-COVID data. Overall, each model has its own strength, and the choice depends on whether the goal is balanced performance or higher accuracy in detecting COVID lesions.
\end{document}
